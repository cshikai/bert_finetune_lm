version: '3.4'

services:
  model: 
    build: ./model 
    # image: 
    stdin_open: true
    tty: true
    volumes:
      - ./model/src:/src
    ports:
      - 8887:8887
      - 6006:6006
    ulimits:
      memlock: -1 # set upper limit for how much memory is locked for the container (-1 means lock as much as the container uses)
    shm_size: 32gb # set upper limit for how much shared memory container can use

    # environment:
    #   NVIDIA_VISIBLE_DEVICES: 0,1
    # runtime: nvidia
    #esources:
      #slimits:
      #sd nvidia.com/gpu: 1
